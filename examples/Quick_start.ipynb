{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf939483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import urllib\n",
    "from dataclasses import dataclass\n",
    "import tensorflowjs as tfjs\n",
    "import json\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b63ee0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  4\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b6ac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading model from GitHub\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://github.com/ur-whitelab/peptide-dashboard/raw/master/models/hemo-rnn/hemolytic_model.h5\",\n",
    "    \"hemolytic_model.h5\",\n",
    ")\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://github.com/ur-whitelab/peptide-dashboard/raw/master/models/hemo-rnn/hemolytic_model.json\",\n",
    "    \"hemolytic_model.json\",\n",
    ")\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://github.com/ur-whitelab/peptide-dashboard/raw/master/examples/pdb_dist.txt\",\n",
    "    \"pdb_dist.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e90005dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk.\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open('hemolytic_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = keras.models.model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model.load_weights(\"hemolytic_model.h5\")\n",
    "print(\"Loaded model from disk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a3fb258f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function counts_aa obtains amino acid counts frequency vector\n",
    "def counts_aa(vec):\n",
    "    counts =  tf.histogram_fixed_width(vec, [0, 20], nbins=21)[1:]\n",
    "    return counts /tf.reduce_sum(counts)\n",
    "# Getting frequecy of observed amino acids\n",
    "with open(\"pdb_dist.txt\", 'r') as f:\n",
    "        # the probabilities in this file are sorted based on the alphabet list above\n",
    "        pdb_dist = f.read().split()\n",
    "        pdb_dist = [float(item) for item in pdb_dist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6334fe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some random seq vectors\n",
    "data = []\n",
    "data_frequency = []\n",
    "for m in range(500):\n",
    "    seq = np.random.choice(range(1,21), size=15, p=pdb_dist)\n",
    "    data.append(seq)\n",
    "    data_frequency.append(counts_aa(seq))\n",
    "data = np.array(data)\n",
    "data_frequency = np.array(data_frequency)\n",
    "# inputs.shape[-1] needs to be 190, so we pad zeros to the end\n",
    "data = np.concatenate([data, np.zeros((data.shape[0], 190-data.shape[-1]))], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6150c4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict([data, data_frequency])\n",
    "y_predict = np.array([1 if x > 0 else 0 for x in y_predict])\n",
    "print(y_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "serverless"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
